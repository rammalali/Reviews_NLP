{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ec7e926-08a9-42e1-bf82-6a2a476faf96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  ./GloVe/Glove_2gb/glove.840B.300d.zip\n",
      "  inflating: ./GloVe/Glove_2gb/glove.840B.300d.txt  \n"
     ]
    }
   ],
   "source": [
    "!unzip ./GloVe/Glove_2gb/glove.840B.300d.zip -d ./GloVe/Glove_2gb/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13fcd871-424b-440f-a2e0-e5c888d021af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_glove_embeddings(file_path):\n",
    "    embeddings = {}\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            vector = np.asarray(values[1:], dtype='float32')\n",
    "            embeddings[word] = vector\n",
    "    return embeddings\n",
    "\n",
    "glove_embeddings_100 = load_glove_embeddings('./GloVe/glove.6B.100d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3dbea73-155b-472a-9f78-3c831f1edc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "word = 'example'\n",
    "word_vector = glove_embeddings_100[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2bf7816-b72c-49f8-9f22-2f0c2378b285",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.12617  ,  0.61724  ,  0.22581  ,  0.39868  ,  0.16111  ,\n",
       "        0.1523   , -0.14715  , -0.29447  , -0.27348  , -0.13753  ,\n",
       "       -0.20898  , -0.73436  ,  0.14144  ,  0.15048  ,  0.09179  ,\n",
       "        0.018613 ,  0.22539  ,  0.15979  , -0.16935  ,  0.42716  ,\n",
       "        0.042284 , -0.3477   , -0.11413  ,  0.12222  , -0.025027 ,\n",
       "       -0.20805  , -0.067264 , -0.2956   , -0.30807  , -0.32903  ,\n",
       "        0.19059  ,  0.77141  , -0.19332  , -0.31069  ,  0.26745  ,\n",
       "        0.32231  ,  0.2065   ,  0.10497  ,  0.49425  , -0.38322  ,\n",
       "       -0.12802  , -0.069906 , -0.14828  ,  0.085369 , -0.18141  ,\n",
       "        0.14688  ,  0.60968  , -0.21131  , -0.29148  , -0.52773  ,\n",
       "        0.59508  ,  0.017369 ,  0.15342  ,  0.81925  , -0.20643  ,\n",
       "       -2.0378   , -0.11884  , -0.16826  ,  1.5288   ,  0.15756  ,\n",
       "       -0.4994   ,  0.39305  ,  0.12672  , -0.10968  ,  1.3671   ,\n",
       "       -0.21006  ,  0.15684  ,  0.0063801,  0.43836  , -0.18765  ,\n",
       "       -0.29088  ,  0.18619  ,  0.085402 ,  0.13985  ,  0.40794  ,\n",
       "       -0.14811  ,  0.26702  , -0.19142  , -0.6189   ,  0.0091217,\n",
       "        0.34971  , -0.24079  , -0.52476  , -0.25071  , -1.5681   ,\n",
       "        0.22101  ,  0.046796 , -0.62616  , -0.043358 , -0.42865  ,\n",
       "       -0.0057843, -0.22611  ,  0.074171 ,  0.091597 , -0.40751  ,\n",
       "       -0.08359  , -0.48413  , -1.0718   ,  0.52827  ,  0.058813 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02b523c2-de0e-4489-a232-d9cd8f058fa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.81961992e-01,  2.17246002e-01,  5.34089997e-01, -1.61714002e-01,\n",
       "        1.34598604e-01,  9.28380024e-02, -6.51241958e-02,  3.09910002e-01,\n",
       "       -1.80134398e-01,  7.02617973e-02, -7.05535986e-02, -2.96088795e-01,\n",
       "        1.51007001e-01, -1.58088000e-01, -2.43440457e-03,  3.63582002e-02,\n",
       "        3.83175201e-01, -2.04482011e-02, -1.74594003e-01,  3.30640797e-01,\n",
       "        1.37514805e-01, -2.91508007e-01,  9.34019834e-03,  1.28722000e-01,\n",
       "        3.64557607e-01, -8.44298817e-02,  8.71437997e-02, -4.30402005e-01,\n",
       "       -2.50883599e-01, -4.86235999e-02, -3.04498200e-01,  6.22098591e-01,\n",
       "       -2.49679975e-02,  7.39772044e-02, -2.74420053e-02,  2.68555801e-01,\n",
       "        1.09224396e-01,  2.38301991e-01,  3.67670026e-02, -2.36533996e-01,\n",
       "       -4.86095986e-01,  1.05131403e-01,  7.25842036e-02, -2.55198994e-01,\n",
       "        7.93462038e-02, -1.22662203e-01,  4.16725993e-01, -4.36089993e-01,\n",
       "       -1.75894001e-01, -6.24897993e-01,  3.83323604e-01, -2.62635799e-01,\n",
       "        4.22643995e-01,  1.02084002e+00, -6.18757984e-01, -2.81080003e+00,\n",
       "        3.25698003e-02, -4.63641992e-01,  1.78095999e+00,  4.31228000e-01,\n",
       "       -1.86570007e-01,  5.04509997e-01, -1.33999403e-01, -4.72655959e-02,\n",
       "        1.10976601e+00, -3.52534989e-01,  3.07775998e-01,  2.26558018e-01,\n",
       "        2.21245003e-01, -2.16579989e-02, -4.14177984e-02, -1.27261999e-01,\n",
       "       -6.52080996e-02, -1.82937598e-01,  2.27795994e-01, -1.77326802e-01,\n",
       "       -2.09810007e-01, -6.09503970e-02, -1.14647801e+00, -3.38647263e-01,\n",
       "        3.81952003e-01,  3.44862018e-02, -5.01500002e-01,  3.06733966e-02,\n",
       "       -1.26407598e+00, -7.73403965e-02,  2.85783600e-01, -4.59390002e-01,\n",
       "        4.32959870e-03, -5.63671994e-01, -4.48858598e-02, -1.80606799e-01,\n",
       "       -3.45479797e-01,  5.40812004e-02,  5.87717601e-02,  1.29288009e-01,\n",
       "       -1.49565800e-01, -7.84304005e-01,  5.60012001e-01,  2.63538603e-01])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def vectorize_preprocessed_text(tokens, embeddings, embedding_dim=100):\n",
    "    text_vector = np.zeros(embedding_dim)\n",
    "    n_tokens = 0\n",
    "    for token in tokens:\n",
    "        if token in embeddings:\n",
    "            text_vector += embeddings[token]\n",
    "            n_tokens += 1\n",
    "    if n_tokens > 0:\n",
    "        text_vector /= n_tokens\n",
    "    return text_vector\n",
    "\n",
    "# Example usage:\n",
    "review = ['this', 'is', 'an', 'example', 'review']\n",
    "vectorize_preprocessed_text(review, glove_embeddings_100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac23efe5-06e6-42fd-948f-0c6e0c54213b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ac464a9-7774-42d1-b900-9f17e4cc74c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>label</th>\n",
       "      <th>text_cleaned</th>\n",
       "      <th>lemmatized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "      <td>1</td>\n",
       "      <td>['bought', 'several', 'vitality', 'canned', 'd...</td>\n",
       "      <td>bought several vitality canned dog food produc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId ProfileName  HelpfulnessNumerator  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW  delmartian                     1   \n",
       "\n",
       "   HelpfulnessDenominator  Score        Time                Summary  \\\n",
       "0                       1      5  1303862400  Good Quality Dog Food   \n",
       "\n",
       "                                                Text  label  \\\n",
       "0  I have bought several of the Vitality canned d...      1   \n",
       "\n",
       "                                        text_cleaned  \\\n",
       "0  ['bought', 'several', 'vitality', 'canned', 'd...   \n",
       "\n",
       "                                     lemmatized_text  \n",
       "0  bought several vitality canned dog food produc...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./datasets/text_cleaned.csv')\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2d8b75f-84be-4050-9922-b88eff9fbe46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hELLO', 'wORLD']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"hELLO wORLD\".split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8019a299-6674-421a-8bc6-858ff3547875",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['vectorized_text'] = df['lemmatized_text'].apply(lambda tokens: vectorize_preprocessed_text(tokens.split(' '), glove_embeddings_100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fdc48f19-3b29-4a91-8a3c-94c2e51a263d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>label</th>\n",
       "      <th>text_cleaned</th>\n",
       "      <th>lemmatized_text</th>\n",
       "      <th>vectorized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "      <td>1</td>\n",
       "      <td>['bought', 'several', 'vitality', 'canned', 'd...</td>\n",
       "      <td>bought several vitality canned dog food produc...</td>\n",
       "      <td>[-0.10477326755170469, 0.4299178531617616, 0.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "      <td>0</td>\n",
       "      <td>['product', 'arrived', 'labeled', 'jumbo', 'sa...</td>\n",
       "      <td>product arrived labeled jumbo salted peanut .....</td>\n",
       "      <td>[-0.2240310903977264, 0.3681404632939534, 0.22...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId ProfileName  HelpfulnessNumerator  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW  delmartian                     1   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK      dll pa                     0   \n",
       "\n",
       "   HelpfulnessDenominator  Score        Time                Summary  \\\n",
       "0                       1      5  1303862400  Good Quality Dog Food   \n",
       "1                       0      1  1346976000      Not as Advertised   \n",
       "\n",
       "                                                Text  label  \\\n",
       "0  I have bought several of the Vitality canned d...      1   \n",
       "1  Product arrived labeled as Jumbo Salted Peanut...      0   \n",
       "\n",
       "                                        text_cleaned  \\\n",
       "0  ['bought', 'several', 'vitality', 'canned', 'd...   \n",
       "1  ['product', 'arrived', 'labeled', 'jumbo', 'sa...   \n",
       "\n",
       "                                     lemmatized_text  \\\n",
       "0  bought several vitality canned dog food produc...   \n",
       "1  product arrived labeled jumbo salted peanut .....   \n",
       "\n",
       "                                     vectorized_text  \n",
       "0  [-0.10477326755170469, 0.4299178531617616, 0.4...  \n",
       "1  [-0.2240310903977264, 0.3681404632939534, 0.22...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28bd8696-d217-4c14-837b-6c56e3f2ff75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(393919,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['vectorized_text'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06565846-2d3f-40a9-bef2-6a2f6640cb99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df['vectorized_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e0ecf1a-8941-408a-b152-8600e8ddfcdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df['vectorized_text'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea0d985b-0c43-431a-8419-1de47b3ac08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(df['vectorized_text'].values.tolist())\n",
    "y = df['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5245576d-2a35-4aae-9a63-729417a54c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(393919, 100) (393919,)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2721fb0c-9dc6-4e18-93b0-9736aad5b86c",
   "metadata": {},
   "source": [
    "## Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a9895fa7-3d09-4abb-b47a-18e0337b9de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.17)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.22) # so 0.22 x 0.83 =~ 0.19 good "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1570331-a359-439d-9c55-2a35ed45719f",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ea7cc743-f754-4c73-b844-749b531a54a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.8207979980536633\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logistic1 = LogisticRegression(solver='liblinear', max_iter=1000, penalty='l2')\n",
    "logistic1.fit(X_train, y_train)\n",
    "\n",
    "val_accuracy = logistic1.score(X_val, y_val)\n",
    "print(\"Validation accuracy:\", val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5ad21072-24ca-445e-8a2e-d71bf74b307f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.37      0.48     16001\n",
      "           1       0.84      0.95      0.89     55929\n",
      "\n",
      "    accuracy                           0.82     71930\n",
      "   macro avg       0.76      0.66      0.69     71930\n",
      "weighted avg       0.80      0.82      0.80     71930\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = logistic1.predict(X_val)\n",
    "report = classification_report(y_val, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e43edc82-0872-4e2a-bc82-d5bc1da4ab09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# param_grid = {\n",
    "#     'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "#     'tol': [1e-3, 1e-4, 1e-5],\n",
    "#     'penalty': ['l1', 'l2', 'elasticnet'],\n",
    "#     'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "#     'max_iter': [200]\n",
    "# }\n",
    "\n",
    "\n",
    "# logistic_forGrid = LogisticRegression()\n",
    "# logistic_grid_search = GridSearchCV(logistic_forGrid, param_grid, cv=5, scoring='accuracy', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf3e7b9-e16a-4b28-aefc-11297b9bbda3",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "172f11a0-bade-4197-880f-2935af241de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier: Validation accuracy: 0.8028082858334492\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.17      0.28     16001\n",
      "           1       0.81      0.98      0.89     55929\n",
      "\n",
      "    accuracy                           0.80     71930\n",
      "   macro avg       0.78      0.58      0.58     71930\n",
      "weighted avg       0.79      0.80      0.75     71930\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "RFC1 = RandomForestClassifier(n_estimators=100)\n",
    "RFC1.fit(X_train, y_train)\n",
    "\n",
    "val_accuracy_RFC = RFC1.score(X_val, y_val)\n",
    "print(\"RandomForestClassifier: Validation accuracy:\", val_accuracy_RFC)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = RFC1.predict(X_val)\n",
    "report = classification_report(y_val, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70683972-08a8-4eac-95d9-0f24fff6cb69",
   "metadata": {},
   "source": [
    "## Cosine Similarity - KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "84dc4522-535f-4a65-8637-0e0571d531f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics.pairwise import cosine_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "95811f90-c250-4ddd-bf30-aa2865b0664e",
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN = KNeighborsClassifier(n_neighbors=7, metric= 'precomputed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "01517a00-d3a4-4343-816c-217241433c72",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 485. GiB for an array with shape (255022, 255022) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m cosine_dist_train \u001b[38;5;241m=\u001b[39m \u001b[43mcosine_distances\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m cosine_dist_train\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/metrics/pairwise.py:1000\u001b[0m, in \u001b[0;36mcosine_distances\u001b[0;34m(X, Y)\u001b[0m\n\u001b[1;32m    974\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute cosine distance between samples in X and Y.\u001b[39;00m\n\u001b[1;32m    975\u001b[0m \n\u001b[1;32m    976\u001b[0m \u001b[38;5;124;03mCosine distance is defined as 1.0 minus the cosine similarity.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    997\u001b[0m \u001b[38;5;124;03mscipy.spatial.distance.cosine : Dense matrices only.\u001b[39;00m\n\u001b[1;32m    998\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    999\u001b[0m \u001b[38;5;66;03m# 1.0 - cosine_similarity(X, Y) without copy\u001b[39;00m\n\u001b[0;32m-> 1000\u001b[0m S \u001b[38;5;241m=\u001b[39m \u001b[43mcosine_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1001\u001b[0m S \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1002\u001b[0m S \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/metrics/pairwise.py:1401\u001b[0m, in \u001b[0;36mcosine_similarity\u001b[0;34m(X, Y, dense_output)\u001b[0m\n\u001b[1;32m   1398\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1399\u001b[0m     Y_normalized \u001b[38;5;241m=\u001b[39m normalize(Y, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m-> 1401\u001b[0m K \u001b[38;5;241m=\u001b[39m \u001b[43msafe_sparse_dot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_normalized\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_normalized\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdense_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdense_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1403\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m K\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/utils/extmath.py:189\u001b[0m, in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    187\u001b[0m         ret \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(a, b)\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 189\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    192\u001b[0m     sparse\u001b[38;5;241m.\u001b[39missparse(a)\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m sparse\u001b[38;5;241m.\u001b[39missparse(b)\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m dense_output\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(ret, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoarray\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    196\u001b[0m ):\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39mtoarray()\n",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate 485. GiB for an array with shape (255022, 255022) and data type float64"
     ]
    }
   ],
   "source": [
    "cosine_dist_train = cosine_distances(X_train, X_train)\n",
    "cosine_dist_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9684a98d-743d-4f36-ab9e-9dd550c07933",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.8)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.7) # so 0.32 x 0.6 =~ 0.24  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2dfd0544-2072-4353-8131-d4df27784835",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.10614535, 0.09898691, ..., 0.12465802, 0.10094231,\n",
       "        0.07316734],\n",
       "       [0.10614535, 0.        , 0.11636677, ..., 0.05802315, 0.05676819,\n",
       "        0.05852211],\n",
       "       [0.09898691, 0.11636677, 0.        , ..., 0.10655886, 0.17360541,\n",
       "        0.1199342 ],\n",
       "       ...,\n",
       "       [0.12465802, 0.05802315, 0.10655886, ..., 0.        , 0.11585894,\n",
       "        0.08600499],\n",
       "       [0.10094231, 0.05676819, 0.17360541, ..., 0.11585894, 0.        ,\n",
       "        0.06156444],\n",
       "       [0.07316734, 0.05852211, 0.1199342 , ..., 0.08600499, 0.06156444,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_dist_train = cosine_distances(X_train, X_train)\n",
    "cosine_dist_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6c9f7382-c10f-48fa-aef9-09d17054e624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(metric=&#x27;precomputed&#x27;, n_neighbors=7)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(metric=&#x27;precomputed&#x27;, n_neighbors=7)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier(metric='precomputed', n_neighbors=7)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNN.fit(cosine_dist_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "069dbc5a-f034-4d6d-b771-bd0abcf3ce74",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 55.5 GiB for an array with shape (315136, 23634) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m cosine_dist_test \u001b[38;5;241m=\u001b[39m \u001b[43mcosine_distances\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/metrics/pairwise.py:1000\u001b[0m, in \u001b[0;36mcosine_distances\u001b[0;34m(X, Y)\u001b[0m\n\u001b[1;32m    974\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute cosine distance between samples in X and Y.\u001b[39;00m\n\u001b[1;32m    975\u001b[0m \n\u001b[1;32m    976\u001b[0m \u001b[38;5;124;03mCosine distance is defined as 1.0 minus the cosine similarity.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    997\u001b[0m \u001b[38;5;124;03mscipy.spatial.distance.cosine : Dense matrices only.\u001b[39;00m\n\u001b[1;32m    998\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    999\u001b[0m \u001b[38;5;66;03m# 1.0 - cosine_similarity(X, Y) without copy\u001b[39;00m\n\u001b[0;32m-> 1000\u001b[0m S \u001b[38;5;241m=\u001b[39m \u001b[43mcosine_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1001\u001b[0m S \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1002\u001b[0m S \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/metrics/pairwise.py:1401\u001b[0m, in \u001b[0;36mcosine_similarity\u001b[0;34m(X, Y, dense_output)\u001b[0m\n\u001b[1;32m   1398\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1399\u001b[0m     Y_normalized \u001b[38;5;241m=\u001b[39m normalize(Y, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m-> 1401\u001b[0m K \u001b[38;5;241m=\u001b[39m \u001b[43msafe_sparse_dot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_normalized\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_normalized\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdense_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdense_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1403\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m K\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/utils/extmath.py:189\u001b[0m, in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    187\u001b[0m         ret \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(a, b)\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 189\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    192\u001b[0m     sparse\u001b[38;5;241m.\u001b[39missparse(a)\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m sparse\u001b[38;5;241m.\u001b[39missparse(b)\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m dense_output\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(ret, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoarray\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    196\u001b[0m ):\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39mtoarray()\n",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate 55.5 GiB for an array with shape (315136, 23634) and data type float64"
     ]
    }
   ],
   "source": [
    "cosine_dist_test = cosine_distances(X_test, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ecc6fbfb-594a-47ac-a91f-62913710bf8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_garbage, X_test, y_garbage, y_test = train_test_split(x, y, test_size=0.04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fee7d00b-93e2-4842-a06e-808f93143ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_dist_test = cosine_distances(X_test, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a7ced739-cf7f-497f-a7c0-dfd68cbcb8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = KNN.predict(cosine_dist_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "23f2b00d-7e4f-43ac-b1d6-93bce9a3c324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7859364092149521\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9658a940-271d-4440-9816-c265c4735b53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
